\chapter{Neural Net based Electronics Response Modeling}
\label{chap:elect_resp}

\section{Introduction}
As discussed in chapter \ref{chap:detectors}, HPGe detectors provide excellent energy resolution and good pulse-shape–based event identification, making them critical for low-background physics searches such as neutrinoless double-beta decay $0\nu\beta\beta$. However, the signal from HPGe detector must pass through an electronic readout chain consisting of components such as preamplifier, filtering stages, and digitization. These electronics transform the signal in ways that can distort pulse shapes, alter the rise time, and add overshoots/undershoots or baseline shifts. Accurately modeling this transformation is crucial for producing realistic pulse-shape simulations.

This chapter begins with an overview of typical HPGe detector readout electronics. It is followed by an overview of {\Ltwo}  electronics and how electronics introduce distortions in waveforms, called electronics response. This is followed by challenges in modeling the electronics response and a neural network approach to it.

\section{{\Ltwo} readout electronics}

{\Ltwo} uses a resistive-feedback charge-sensitive amplifier (CSA) to minimize noise and achieve low radioactive background. The first stage is referred to as the Low-Mass Front End (LMFE). LMFE is placed inside the experiment’s liquid argon cryostat, only a few millimeters from the point contact of each HPGe detector \cite{Willers_2020}. LMFE is thus constructed with high radio-pure materials with tolerance typically on the order of $1\mu$ Bq per channel. LMFE builds upon one developed by {\MJD} and is produced using Suprasil substrates, titanium-gold (TiAu) traces, an in-die junction field effect transistor (JFET, Moxtek MX11), and thin-film amorphous germanium feedback resistors that can operate at cryogenic temperatures. 

\begin{figure}[!htb]%[htb!]
  %[trim={left bottom right top},clip]
    \includegraphics[width=0.99\linewidth,trim={1pc 0pc 1pc 0pc},clip]{ch6/figs/l200_elec_diagram.jpg}
    \caption{A Schematic of the Demonstrator signal readout chain.\cite{Willers_2020}}
   \label{fig:l200_elec_model}
\end{figure}

\begin{figure}[!htb]%[htb!]
  %[trim={left bottom right top},clip]
  \centering
    \includegraphics[width=0.32\linewidth,trim={1pc 0pc 1pc 0pc},clip]{ch6/figs/l200_det_close_up.jpg}
    \includegraphics[width=0.32\linewidth,trim={1pc 0pc 1pc 0pc},clip]{ch6/figs/l200_elec_picture.jpg}
    \includegraphics[width=0.32\linewidth,trim={1pc 0pc 1pc 0pc},clip]{ch6/figs/l200_flashcam_crate.jpg}
    \caption{Picture of the front end electronics of {\Ltwo}. Left show close up of the detector with the LMFE, middle shows the detector strings front end electronics and right shoes the Flashcam crates in the DAQ rack. Photo: Michael Willers}
   \label{fig:l200_elec}
\end{figure}



The second amplifier is based on a folded cascode arrangement and located $30$–$150$ cm from the detector to provide additional gain and to convert the signal to a differential output. This stage can tolerate slightly higher radioactivity levels of $50\mu$ Bq per channel and is built using screened commercial surface-mount components on Kapton circuit boards called the CC4. The second stage is connected to the the data acquisition system using a $\thicksim 10$ m long transmission line. An active buffer called Head Electronics receives the signals from the second stage. This adjusts offsets and gain while providing impedance matching. Finally the signals is fed into a FlashCam where the signal is digitized and stored for analysis.

Together these design choices enable sub 3keV FWHM energy resolution in the ROI at $Q_{\beta\beta}$ 2039 keV while contributing minimally to the overall radioactive background. They also enable a fast rise time of $\thicksim 0.100$ ns which allows pulse shape discrimination of the signals. Additionally, they have a high range of up to 10 MeV that enables measuring high-energy alpha decays which would provide additional information for background modelling.

\section{Electronics Influence on Waveforms}

Despite careful design and component selection, the LEGEND-200 electronics chain inevitably modifies the detector’s raw current signals. Figure~\ref{fig:sim_data_comp} shows some of these effects by comparing a simulated waveform (blue) with a corresponding real data pulse (red).

The baseline is the region before $t_0$, the start of the wavefrom. Ideally, this baseline should remain near a stable DC offset determined by the preamplifier’s quiescent operating point. Two factors can shift or tilt the baseline. First, a slow high-pass filter effect (on the order of milliseconds) arises from the capacitive coupling between the first and second preamplifier stages. Second, if events occur in rapid succession, the tail from one pulse may not fully decay before the next arrives, causing the baseline to drift or undershoot. These shifts become especially noticeable at higher rates, leading to soft pile-up where partial overlap deforms the apparent starting level of subsequent waveforms. 

The rising edge, shown in orange region, is the most visible part of the waveform resulting from movement of electrons and holes from the energy deposition. The long cable runs and folded-cascode amplifier stages introduce a finite bandwidth, effectively acting as a low-pass filter that damps the highest-frequency components. As a result, the observed rising edge in real data tends to be broader and smoother than in simulations. 

The RC decay tail (light blue region) develops from the CSA feedback network in the LMFE, where the detector current is integrated on a feedback capacitor and slowly discharged by the feedback resistor. The second stage of amplification has a shorter differentiator-like time constant, further modifying the decay shape seen in data. Taken together, these processes create a pulse with a multi-exponential decay. 


Overall, the three waveform regions, baseline, rising edge, and tail, are each influenced by different parts of the LEGEND-200 electronics chain. Circuit simulations such as SPICE can reproduce some of the bulk features but minute responses such as parasitic inductance, JFET nonlinearity, or thermal drifts are hard to model.

\begin{figure}[!htb]%[htb!]
  %[trim={left bottom right top},clip]
    \includegraphics[width=\linewidth,trim={4cm 0pc 3.5cm 0pc},clip]{ch6/figs/wf_comp_sim_data.png}
    \caption{Comparison of a simulated waveform with a real data pulse.}
    \label{fig:sim_data_comp}
\end{figure}

\section{Challenges in Modeling Electronics Response}

Pulse shape simulation aims at generating waveforms that are similar to the actual detector waveforms. Having a direct mapping between a simulated pulse and its corresponding incident particle would enable applying the same cuts to the simulations as data. This would help us understand the efficiency of cuts such as multisite cuts ~\cite{AvsE}.  


A frequency-dependent response function must then be added to the simulations to reproduce the detector response. The electronic transfer function describes the series of linear transformations on the detector output signal by the readout electronic components. The electron response is typically derived from the circuit's response to a step function input. However, the experimental conditions commonly used in low-background and cryogenic experiments, such as long cable runs and extended amplification chains, make it difficult to generate waveforms close to the detector. This poses significant challenges in measuring the electronics response directly. Fig. \ref{fig:l200_elec} show the front end electronics of {\Ltwo}, a contrast from Fig \ref{fig:l200_elec} showing how in practice the electronics setup can be quite complicated.

While simulations can account for some of these effects, they are inherently limited by assumptions. These assumptions often fail to capture the complexities of real-world behavior, such as detector-specific anomalies, non-linearity in the amplification chain, or subtle effects from experimental conditions. Furthermore, inaccuracies in simulation assumptions, such as incorrect drift velocity calculations in the electric field or oversimplified charge cloud dynamics, can exacerbate discrepancies between simulated and real detector waveforms. The result is a persistent mismatch between simulated and measured waveforms, necessitating ad-hoc corrections. 

Heuristic methods are often used to approximate the electronic response. Current experiments avoid detailed modeling of electronics by calculating reconstruction parameters directly from Monte Carlo particle-interaction simulations, relying on heuristic methods to meet most of their simulation needs ~\cite{Ben_Thesis,Sam_Thesis}. These methods fall short in failing to account for detector-by-detector variations and operational changes in experimental conditions, which can evolve over time. This lack of adaptability introduces systematic errors and limits the fidelity of pulse shape simulations.


Transfer Learning is an approach to directly learning the translations between each simulated pulse and its corresponding detector pulse. In the next section, we present a new neural network model called Cyclic Positional U-Net~(CPU-Net) that allows learning the translations from data and applying them to simulations without explicit programming.

\section{Machine Learning Based Electronics Modeling}
\subsection{Mathematical Formulism}
The goal of learning electronics transfer function from data and adding them to simulation can be re-formulated under the transfer learning framework. The goal is to translate simulated waveforms into real waveforms by learning the differences between them.

In this approach, the source domain $\mathcal{D}_{Source}$ represents the simulated waveforms. It includes features of the simulated waveforms, such as energy, maximal current amplitude, tail slope, etc. These parameters form a feature space ($\mathcal{Y}$) and follow a probability distribution $(P(Y))$. The source task refers to the relationship between the reconstruction parameters $(Y)$ in the source domain and the simulated waveforms ($\mathcal{X}$). This is captured by the conditional distribution $P(X|Y)$, which describes how each parameter set $(Y)$ maps to a specific simulated waveform $(X)$. For instance, if we know the energy and rise time of a pulse, the source task models how these parameters produce a simulated waveform. Mathematically, we write source domain as:

\begin{equation}
    \mathcal{D}_{Source}=\{\mathcal{Y},P(Y)\}\qquad 
    \label{eqn:source_domain}
\end{equation}
Then the reconstruction parameters are written as:
 \begin{equation}
     Y=\{\mathrm{E},I_{\mathrm{max}},c_{\mathrm{tail}}...\}\in \mathcal{Y}
 \end{equation}

The source task is written as:
\begin{equation}
    \mathcal{T}_{Source}=\{\mathcal{X},P(X|Y)\} \qquad X\in \mathcal{X}
    \label{eqn:source_task}
\end{equation}


Similarity target domain $\mathcal{D}_{Target}$ represents the detector data waveform. It contains the feature space $\mathcal{Y'}$ whose elements follow the probability distribution $P(Y')$, $Y'$ are the reconstruction parameters of detector waveforms $(X')$.

\begin{equation}
\mathcal{D}_{Target}=\{\mathcal{Y}',P(Y')\}
\end{equation}
\begin{equation}
\mathcal{T}_{Target}=\{\mathcal{X}',P(X'|Y')\}
\end{equation}

Pulse shape simulation typically to learn $P(X'|Y')$ and apply it to an arbitrary $Y$ in $\mathcal{D}_{Source}$ so that the generated simulated waveform $(\mathcal{X})$ is similar to the data waveforms $\mathcal{X}'$. For example one can fit the tail slope of the detector pulses to determine the decay constant and add a pole with that time decay to the simulation to replicate the data. 

This method requires complicated modeling and characterization data-taking, along with computationally expensive fitting procedures in high-dimensional, highly degenerate parameter space~\cite{Ben_Thesis,Sam_Thesis}. Instead we can avoid the direct modification of  $P(X|Y)$ by introducing a Ad-hoc Translation Network~(ATN):
\begin{equation}
\Lambda = \{\hat{\mathcal{X}}, P(\hat{X}\mid X)\}\qquad \hat{X}\in \hat{\mathcal{X}}
\label{eqn:atn}
\end{equation}
ATN accepts an input pulse $X$ and translates it to an output pulse $\hat{X}$. This transformation is learned from a large sample of data wavefroms. The collection of transformed output $\hat{\mathcal{X}}$ shoud be very similar to $\mathcal{X}'$ after training, so that by combining the ATN and $\mathcal{T}_{Source}$, we can replicate $\mathcal{T}_{Target}$:
\begin{equation}
    \mathcal{T}_{Target}=\Lambda \mathcal{T}_{Source} ,
    \label{eqn:atn_task}
\end{equation}
which allows us to learn the features of $\mathcal{T}_{Target}$ without explicit programming. For a model to be deemed accurate, it must fulfill two criteria: it should replicate the ensemble distributions of the dataset accurately and maintain the integral detector physics embodied within each pulse. In the next section we discus two neural networks that will help us train the ATN.


% precisely reproduce $\mathcal{T}_{Target}$ without modifying  $P(X|Y)$.

\begin{figure}[htb!]
\centering
    \includegraphics[width=0.7\linewidth]{ch6/figs/unet.png}
    \label{fig:cpunet}
    % \hspace{0.05\linewidth}
    \caption{Schematic diagram of Positional U-Net~(PU-Net). The blue line represents the contracting path. Positional encoding maps at the same level are of the same shape. }
   \label{fig:network_schematic}
\end{figure}

%Unlike Reference~\cite{VAE}, we did not use  Kullback-Leibler Divergence to regulate the reparameterized random distribution.


\subsection{Positional U-Net}

We explored using U-Net~\cite{UNet}, a convolutional neural network initially developed for biomedical image segmentation, as the baseline model when designing the ATN. U-Net contains $n$ convolutional layers to encode each pulse into a feature vector, then uses $n$ upsample layers to decode the feature vector back to an output with the same length. In addition, $n$ contracting paths are established between each pair of convolutional layers and upsample layer at the same level. This network structure allows information at different levels to flow to the decoding part, providing maximal reconstruction efficiency. The Positional U-Net structure is depicted in the Fig. ~\ref{fig:network_schematic}, where the tensor shape at each stage is also denoted. The Conv1d module in Figure~\ref{fig:network_schematic} is a series of layers, as shown in Figure~\ref{fig:detail_network}. Within this module, the kernel size is an important hyperparameter to control the reception field of CNN layers, and the padding is added to guarantee the same input and output shape. Max pooling is used in all Conv1d modules but the first one to increase the reception field. 
\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.3\linewidth,trim={0pc 0pc 0pc 0pc},clip]{ch6/figs/conv1d.png}
    \caption{The layer-wise breakdown of the Conv1d Module in Figure~\ref{fig:network_schematic}.}
    \label{fig:cov1d_break_down}
\end{figure}

During initial testing we observed that conventional U-Net does not reproduce the tail of the waveform due to the lack of positional information in intermediate layer outputs. Therefore, we developed a new Positional U-Net~(PU-Net) model with layer-wise positional encoding maps $\mathcal{M}_{\mathrm{position}}$ inspired by the Transformer model~\cite{Transformer}. $\mathcal{M}_{\mathrm{position}}$ contains sine and cosine functions with different frequencies. Since each U-Net layer outputs a tensor with a different shape, $\mathcal{M}_{\mathrm{position}}$ must be generated separately for each layer and added to the layer output, as shown in Figure~\ref{fig:network_schematic}. The positional encoding for each position $p$ and dimension $i$ is defined as:

\begin{equation}
\mathcal{M}_{\mathrm{position}}(p, 2i) = \sin\left(\frac{p}{10000^{\frac{2i}{\mathcal{d}_{\mathcal{ch}}}}}\right), \quad
\mathcal{M}_{\mathrm{position}}(p, 2i+1) = \cos\left(\frac{p}{10000^{\frac{2i}{\mathcal{d}_{\mathcal{ch}}}}}\right)
\label{eqn:positional_encoding}
\end{equation}

Finally we added a re-parameterization trick to the bottom of PU-Net. The trick was developed in the Variational Autoencoder paper~\cite{VAE} to sample from random space while preserving the gradient flow. Reference~\cite{AAE} pointed out that this trick has the ability to increase the stochasticity of machine learning models. Based on our experiments, an increased stochastically helps the model learn the reconstruction parameters' distributions better.

\subsection{RNN Discriminator}~\label{subapp:RNN}
A attention-coupled recurrent neural network (RNN)\cite{attention} is an ideal model for task involving time series data because position is intrinsically enforced by RNN. We developed a bidirectional RNN that adopts a Gated Recurrent Unit~\cite{GRU} as the internal structure. The input raw waveforms are first embedded with $m=128$, and the RNN yields a 64-dimensional output $\vec{I}(t)$ at each intermediate step $t$ as well as a final output  $\vec{F}$. We then use an attention mechanism~\cite{attention} can boost the performance of RNN by allowing it to focus on different parts of the waveforms such as rising edge during different steps in the training. The attention mechanism contains an attention matrix A of dimension (64,64), which is used to calculate the attention score between $\vec{F}$ and each $\vec{I}(t)$:
\begin{equation}
    s(t) = \mathrm{Softmax}[\vec{I}(t) A \vec{F}]
\end{equation}
A context vector is produced by summing $\vec{I}(t)$ with the weight $s(t)$ at each $t$. Finally, the context vector and the final output vector are concatenated and fed into a series of fully connected layers to produce a single output. The RNN discriminator is depicted in the in Fig. ~\ref{fig:detail_network}.

\begin{figure}[htb!]
    \centering

    \includegraphics[width=0.7\linewidth,trim={0pc 0pc 0pc 0pc},clip]{ch6/figs/rnnAttention.png}
    \caption{The attention coupled RNN discriminator.}
    \label{fig:detail_network}
\end{figure}



